{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06cb761b",
   "metadata": {},
   "source": [
    "# RAG from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c5f8cc",
   "metadata": {},
   "source": [
    "**Cài đặt thư viện**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "550340f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyPDF2 import PdfReader\n",
    "from typing import List, Dict, Any"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5764fc7d",
   "metadata": {},
   "source": [
    "- Nhận pdf_path theo kiểu string\n",
    "- Khởi tạo ds lưu trữ pdf_pages\n",
    "- \"rb\" - read binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "80399cf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_path: str) -> str:\n",
    "    pdf_pages = []\n",
    "    with open(pdf_path, \"rb\") as file:\n",
    "        pdf_reader = PdfReader(file) # Hàm đọc file PDF\n",
    "        for page in pdf_reader.pages: #đọc từng trang trong file PDF\n",
    "            text = page.extract_text()\n",
    "            pdf_pages.append(text)\n",
    "\n",
    "    pdf_text = \"\\n\".join(pdf_pages)\n",
    "\n",
    "    return pdf_text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1c777a",
   "metadata": {},
   "source": [
    "- Thư viện để thực hiện HTTP requests\n",
    "- gửi request để nhận response --> Tải pdf từ link url về\n",
    "- pdf_path để đặt tên cái pdf đó\n",
    "- \"wb\" - write binary\n",
    "- viết nội dung vào file local ở pdf_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a04f2364",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests \n",
    "\n",
    "pdf_url = 'https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf'\n",
    "response = requests.get(pdf_url)\n",
    "\n",
    "pdf_path = 'attention_is_all_you_need.pdf'\n",
    "with open(pdf_path, 'wb') as file:\n",
    "    file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "437e58c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pdf_text = extract_text_from_pdf(pdf_path[:300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b90361b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attention Is All You Need\n",
      "Ashish Vaswani\u0003\n",
      "Google Brain\n",
      "avaswani@google.comNoam Shazeer\u0003\n",
      "Google Brain\n",
      "noam@google.comNiki Parmar\u0003\n",
      "Google Research\n",
      "nikip@google.comJakob Uszkoreit\u0003\n",
      "Google Research\n",
      "usz@google.com\n",
      "Llion Jones\u0003\n",
      "Google Research\n",
      "llion@google.comAidan N. Gomez\u0003y\n",
      "University of Toronto\n",
      "aidan@c\n"
     ]
    }
   ],
   "source": [
    "print(pdf_text[:300])  # In ra 300 ký tự đầu tiên của văn bản PDF để kiểm tra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ca1c0e",
   "metadata": {},
   "source": [
    "# Chunk Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d2b7145",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c2657e",
   "metadata": {},
   "source": [
    "- Trả về danh sách các đoạn văn bản"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b8593c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def text_chunk(text:str, max_length: int = 1000) -> List[str]:\n",
    "    sentences = deque(re.split(r'(?<=[.!?])\\s+', text.replace('\\n', ' ')))\n",
    "    chunks = []\n",
    "    chunk_text = \"\"\n",
    "    while sentences:\n",
    "        sentence = sentences.popleft().strip()\n",
    "        if len(chunk_text) + len(sentence) > max_length and chunk_text:\n",
    "            chunks.append(chunk_text)\n",
    "            chunk_text = sentence\n",
    "        else:\n",
    "            chunk_text += \" \" + sentence\n",
    "    if chunk_text: \n",
    "        chunks.append(chunk_text)\n",
    "    return chunks                                              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc6c36e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_chunk(pdf_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9cac62bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks =36\n",
      " Attention Is All You Need Ashish Vaswani\u0003 Google Brain avaswani@google.comNoam Shazeer\u0003 Google Brain noam@google.comNiki Parmar\u0003 Google Research nikip@google.comJakob Uszkoreit\u0003 Google Research usz@google.com Llion Jones\u0003 Google Research llion@google.comAidan N. Gomez\u0003y University of Toronto aidan@cs.toronto.eduŁukasz Kaiser\u0003 Google Brain lukaszkaiser@google.com Illia Polosukhin\u0003z illia.polosukhin@gmail.com Abstract The dominant sequence transduction models are based on complex recurrent or convolutional neural networks that include an encoder and a decoder. The best performing models also connect the encoder and decoder through an attention mechanism. We propose a new simple network architecture, the Transformer, based solely on attention mechanisms, dispensing with recurrence and convolutions entirely. Experiments on two machine translation tasks show these models to be superior in quality while being more parallelizable and requiring signiﬁcantly less time to train.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Number of chunks ={len(chunks)}\")\n",
    "print(chunks[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79250df3",
   "metadata": {},
   "source": [
    "# Vector Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ad1d05be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from chromadb.api.models import Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a830a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nguye\\OneDrive\\Tài liệu\\GitHub\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "class SentenceTransformerEmbeddingFunction(embedding_functions.EmbeddingFunction):\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"):\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "\n",
    "    def embed(self, texts: List[str]) -> List[List[float]]:\n",
    "        embeddings = self.model.encode(input)\n",
    "        return embeddings.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4025f7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vector_store(db_path: str) -> Collection:\n",
    "    client = chromadb.PersistentClient(path=db_path)\n",
    "    embeddings = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L6-v2\")\n",
    "    db = client.create_collection(\n",
    "        name=\"pdf_chunks\", \n",
    "        embedding_function=embeddings\n",
    "    )\n",
    "    return db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0708b61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import uuid\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
